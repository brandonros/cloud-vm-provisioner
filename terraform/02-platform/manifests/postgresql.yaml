apiVersion: helm.cattle.io/v1
kind: HelmChart
metadata:
  name: postgresql
  namespace: kube-system
spec:
  repo: https://raw.githubusercontent.com/brandonros/hull-wrapper/master/
  chart: hull-wrapper
  targetNamespace: postgresql
  createNamespace: true
  version: 0.2.0
  valuesContent: |-
    hull:
      config:
        general:
          nameOverride: postgresql
          rbac: false
          noObjectNamePrefixes: true
      objects:
        serviceaccount:
          default:
            enabled: false
        configmap:
          postgresql-config:
            data:
              postgresql.conf:
                inline: |
                  # Connection Settings - MASSIVELY INCREASED
                  listen_addresses = '*'
                  max_connections = 2000              # Was 500, now 2000
                  superuser_reserved_connections = 10  # Increased for admin tasks
                  
                  # Memory Settings - USING YOUR 64GB RAM PROPERLY
                  shared_buffers = 16GB               # Was 256MB, now 16GB (25% of RAM)
                  work_mem = 32MB                     # Was 4MB, now 32MB per operation
                  maintenance_work_mem = 2GB          # Was 64MB, now 2GB
                  effective_cache_size = 48GB         # Was 512MB, now 48GB (75% of RAM)
                  huge_pages = try                    # Enable huge pages for better memory management
                  
                  # Parallel Processing - UTILIZE ALL 20 CPUS
                  max_worker_processes = 20           # Match your CPU count
                  max_parallel_workers = 20           # Use all CPUs for parallel queries
                  max_parallel_workers_per_gather = 10 # Half CPUs per query
                  max_parallel_maintenance_workers = 10 # For maintenance operations
                  
                  # Performance Settings - HIGH-END TUNING
                  random_page_cost = 1.1              # SSD optimized
                  effective_io_concurrency = 300      # Was 200, now 300 for high-end storage
                  seq_page_cost = 1                   # Default for SSD
                  
                  # WAL Settings - OPTIMIZED FOR HIGH THROUGHPUT
                  wal_buffers = 64MB                  # Was 16MB, now 64MB
                  wal_writer_delay = 10ms             # Faster WAL writes
                  wal_writer_flush_after = 1MB        # Flush more frequently
                  checkpoint_completion_target = 0.9  # Keep this
                  checkpoint_timeout = 10min          # More frequent checkpoints for high load
                  max_wal_size = 8GB                  # Was 1GB, now 8GB
                  min_wal_size = 2GB                  # Was 80MB, now 2GB
                  
                  # Connection and Statement Timeouts - OPTIMIZED FOR LOAD TESTING
                  statement_timeout = 60s             # Increased from 30s
                  idle_in_transaction_session_timeout = 120s # Increased from 60s
                  lock_timeout = 30s                  # Increased from 10s
                  deadlock_timeout = 1s               # Quick deadlock detection
                  
                  # Logging - MINIMAL FOR PERFORMANCE
                  log_min_duration_statement = 5000   # Only log very slow queries
                  log_connections = off
                  log_disconnections = off
                  log_lock_waits = on                 # Keep for debugging serialization issues
                  log_temp_files = 100MB              # Only log large temp files
                  log_checkpoints = on                # Monitor checkpoint performance
                  
                  # Statistics and Monitoring
                  track_activities = on
                  track_counts = on
                  track_io_timing = on
                  track_functions = pl
                  
                  # Background Writer - AGGRESSIVE TUNING
                  bgwriter_delay = 50ms               # Was 200ms, more aggressive
                  bgwriter_lru_maxpages = 1000        # Was 100, now 1000
                  bgwriter_lru_multiplier = 4.0       # Was 2.0, more aggressive
                  bgwriter_flush_after = 512kB        # Flush smaller chunks more often
                  
                  # Auto-vacuum - TUNED FOR HIGH TRANSACTION VOLUME
                  autovacuum = on
                  autovacuum_max_workers = 6          # Was 3, now 6
                  autovacuum_naptime = 30s            # Was 1min, more frequent
                  autovacuum_vacuum_threshold = 25    # Was 50, more aggressive
                  autovacuum_analyze_threshold = 25   # Was 50, more aggressive
                  autovacuum_vacuum_scale_factor = 0.1 # Was 0.2, more aggressive
                  autovacuum_analyze_scale_factor = 0.05 # Was 0.1, more aggressive
                  autovacuum_vacuum_cost_limit = 2000 # Higher cost limit for faster vacuum
                  
                  # Network settings
                  tcp_keepalives_idle = 300           # More aggressive keepalives
                  tcp_keepalives_interval = 15        # More frequent
                  tcp_keepalives_count = 3
                  
                  # Additional high-performance settings
                  fsync = on                          # Keep data safety
                  full_page_writes = on               # Keep data safety
                  wal_compression = on                # Compress WAL for better throughput
                  
                  # JIT compilation for complex queries
                  jit = on
                  jit_above_cost = 100000
                  jit_optimize_above_cost = 500000
                  
                  # Shared preload libraries for performance extensions
                  shared_preload_libraries = 'pg_stat_statements'
        service:
          postgresql:
            ports:
              postgresql:
                port: 5432
                targetPort: 5432
        statefulset:
          postgresql:
            serviceName: postgresql
            replicas: 1
            
            pod:
              initContainers:
                config-setup:
                  image:
                    repository: postgres
                    tag: 17.5-bookworm
                  command:
                    - /bin/bash
                    - -c
                    - |
                      if [ ! -f "$PGDATA/PG_VERSION" ]; then
                        echo "Initializing database..."
                        docker-entrypoint.sh postgres --version
                        cp /tmp/postgresql.conf "$PGDATA/postgresql.conf"
                        chown postgres:postgres "$PGDATA/postgresql.conf"
                        echo "Custom postgresql.conf copied successfully"
                      else
                        echo "Database already exists, updating config..."
                        cp /tmp/postgresql.conf "$PGDATA/postgresql.conf"
                        chown postgres:postgres "$PGDATA/postgresql.conf"
                      fi
                  env:
                    POSTGRES_PASSWORD:
                      value: "Test_Password123!"
                    PGDATA:
                      value: "/var/lib/postgresql/data/pgdata"
                  volumeMounts:
                    data:
                      name: postgres-data
                      mountPath: /var/lib/postgresql/data
                    config:
                      name: config
                      mountPath: /tmp/postgresql.conf
                      subPath: postgresql.conf
              containers:
                postgresql:
                  image:
                    repository: postgres
                    tag: 17.5-bookworm
                  
                  ports:
                    postgresql:
                      containerPort: 5432
                  
                  env:
                    POSTGRES_PASSWORD:
                      value: "Test_Password123!"
                    PGDATA:
                      value: "/var/lib/postgresql/data/pgdata"
                  
                  # MASSIVE RESOURCE INCREASE - USE YOUR HARDWARE!
                  resources:
                    requests:
                      cpu: "2"      # Instead of 12
                      memory: "8Gi" # Instead of 48Gi
                    limits:
                      cpu: "8"      # Instead of 18
                      memory: "16Gi" # Instead of 56Gi
                  
                  volumeMounts:
                    data:
                      name: postgres-data
                      mountPath: /var/lib/postgresql/data
              
              volumes:
                config:
                  configMap:
                    name: postgresql-config
            
            volumeClaimTemplates:
              - metadata:
                  name: postgres-data
                spec:
                  accessModes:
                    - ReadWriteOnce
                  resources:
                    requests:
                      storage: 8Gi