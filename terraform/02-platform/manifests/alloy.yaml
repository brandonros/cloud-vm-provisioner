apiVersion: helm.cattle.io/v1
kind: HelmChart
metadata:
  name: alloy
  namespace: alloy
spec:
  repo: https://grafana.github.io/helm-charts
  chart: alloy
  targetNamespace: alloy
  createNamespace: true
  version: 0.12.6
  valuesContent: |-
    # Simple Grafana Alloy values for local development with LGTM stack

    # Set up a simple deployment for local development
    controller:
      type: deployment
      replicas: 1
      podAnnotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "12345"

    # Basic Alloy configuration
    alloy:
      # Use HTTP scheme for local development
      listenAddr: 0.0.0.0
      listenPort: 12345
      
      # OpenTelemetry collector config for receiving metrics, traces, and logs
      configMap:
        create: true
        content: |
          // Grafana Alloy Configuration for LGTM Stack
          // This configuration demonstrates how to collect and ship metrics, logs, and traces

          // Local file discovery for logs
          local.file_match "system_logs" {
            path_targets = [{"__path__" = "/var/log/**/*.log"}]
          }

          // Logs processing pipeline
          loki.source.file "local_logs" {
              targets    = local.file_match.system_logs.targets
              forward_to = [loki.write.local.receiver]
          }

          // Loki write endpoint configuration
          loki.write "local" {
              endpoint {
                  url = "http://loki.loki:3100/loki/api/v1/push"
              }
          }

          // Built-in Unix (Node) Exporter - replaces standalone node_exporter
          // prometheus.exporter.unix "local_system" {
          //     include_exporter_metrics = true
          //     
          //     // Optional: Configure specific collectors
          //     set_collectors = ["cpu", "meminfo", "diskstats", "filesystem", "netdev", "loadavg"]
          //     
          //     // Optional: Enable additional collectors
          //     enable_collectors = ["processes"]
          //     
          //     // Optional: Disable expensive collectors
          //     disable_collectors = ["arp", "bcache", "systemd"]
          // }

          // Scrape the built-in unix exporter
          // prometheus.scrape "node_metrics" {
          //     targets = prometheus.exporter.unix.local_system.targets
          //     forward_to = [prometheus.remote_write.mimir.receiver]
          //     scrape_interval = "15s"
          //     job_name = "node-exporter"
          // }

          // Scrape external node exporter - replace with your actual service name and namespace
          prometheus.scrape "external_node_exporter" {
              targets = [
                  {
                      "__address__" = "node-exporter-prometheus-node-exporter.node-exporter:9100",
                      "job" = "external-node-exporter",
                  },
              ]
              forward_to = [prometheus.remote_write.mimir.receiver]
              scrape_interval = "15s"
              job_name = "external-node-exporter"
          }

          // kube-state-metrics
          prometheus.scrape "kube_state_metrics" {
              targets = [
                  {
                      "__address__" = "kube-state-metrics.kube-state-metrics:8080",
                      "job" = "kube-state-metrics",
                  },
              ]
              forward_to = [prometheus.remote_write.mimir.receiver]
              scrape_interval = "15s"
              job_name = "kube-state-metrics"
          }

          // cAdvisor
          prometheus.scrape "cadvisor_static" {
              targets = [
                  {
                      "__address__" = "asusrogstrix:10250",
                      "job" = "cadvisor",
                      "node" = "asusrogstrix",
                  },
              ]
              forward_to = [prometheus.remote_write.mimir.receiver]
              scrape_interval = "15s"
              job_name = "cadvisor"
              metrics_path = "/metrics/cadvisor"
              scheme = "https"
              bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"
              tls_config {
                  insecure_skip_verify = true
              }
          }

          // postgres-exporter
          prometheus.scrape "postgres_exporter" {
              targets = [
                  {
                      "__address__" = "postgres-exporter-prometheus-postgres-exporter.postgres-exporter:80",
                      "job" = "postgres-exporter",
                  },
              ]
              forward_to = [prometheus.remote_write.mimir.receiver]
              scrape_interval = "15s"
              job_name = "postgres-exporter"
          }

          // Mimir remote write configuration
          prometheus.remote_write "mimir" {
              endpoint {
                  url = "http://mimir-gateway.mimir/api/v1/push"
              }
          }

          // OpenTelemetry collector for traces
          otelcol.receiver.otlp "default" {
              grpc {
                  endpoint = "0.0.0.0:4317"
              }
              
              http {
                  endpoint = "0.0.0.0:4318"
              }
              
              output {
                  metrics = [otelcol.processor.batch.default.input]
                  logs    = [otelcol.processor.batch.default.input]
                  traces  = [otelcol.processor.batch.default.input]
              }
          }

          // Batch processor to optimize throughput
          otelcol.processor.batch "default" {
              output {
                  metrics = [otelcol.exporter.prometheus.mimir.input]
                  logs    = [otelcol.exporter.loki.local.input]
                  traces  = [otelcol.exporter.otlphttp.tempo.input]
              }
          }

          // Prometheus exporter to convert OTLP metrics to Prometheus format
          otelcol.exporter.prometheus "mimir" {
              forward_to = [prometheus.remote_write.mimir.receiver]
          }

          // Loki exporter for logs
          otelcol.exporter.loki "local" {
              forward_to = [loki.write.local.receiver]
          }

          // Tempo trace exporter
          otelcol.exporter.otlphttp "tempo" {
              client {
                  endpoint = "http://tempo.tempo:4318"
              }
          }

          // Optional: Application metrics from a sample service
          prometheus.scrape "example_app" {
              targets = [
                  {
                      "__address__" = "example-app:8080",
                      "job" = "example-service",
                  },
              ]
              forward_to = [prometheus.remote_write.mimir.receiver]
          }

          // Health check and debugging components
          logging {
              level  = "info"
              format = "logfmt"
          }

      # Add extra ports for OTLP receivers
      extraPorts:
        - name: "otlp-grpc"
          port: 4317
          targetPort: 4317
          protocol: "TCP"
        - name: "otlp-http"
          port: 4318
          targetPort: 4318
          protocol: "TCP"

    # Enable service for accessing Alloy from your applications
    service:
      enabled: true
      type: ClusterIP
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "12345"

    # Simple resource requests for local development
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        memory: 512Mi

    # Default image settings
    image:
      repository: grafana/alloy
      pullPolicy: IfNotPresent

    # Create RBAC resources
    rbac:
      create: true

    # Create ServiceAccount
    serviceAccount:
      create: true

    # Configure auto-reload for configuration changes
    configReloader:
      enabled: true
